# Laboratorio 25-C: "Backend de Redis con dos réplicas"
 
# Este laboratorio aprenderemos a desplegar una app con in Fronend y un  Backend de Redis con dos réplicas (master y slave)
# Requisitos:
#
#   1) Una máquina virtual con Ubuntu 20.04 LTS a la que poder hacer ssh.
#
#   2)  Tener instalado el runtime de podman. (ver lab-06-A.txt, Ejercicio 1 y 2)


##################################################
# Ejercicio 1:  Despliegue del maestro de Redis. #
##################################################

# Vamos desplegar una app con un frontend y backend de redis (un master y dos réplicas)
# Cambiamos al directorio de trabajo.

cd ~/k8s_desarrolladores/25

# Desplegamos el backend del maestro de redis. Abrimos el achivo 'lab-25-redis-master-deployment.yaml'


code lab-25-redis-master-deployment.yaml

# El contenido a destacar de este archivo lo comentamos a continuación:
#
# Línea 2:      Es un 'deployment'
#
# Línea 4:      Asignamos el nombre de 'redis-master-deployment'
#
# Línea 6:      Se define la etiqueta 'app: redis'
#
# Líneas 8-12:  Importante: Hasta el momento hemos usado una sola etiqueta para asociar el deployment a la plantilla
#               de pod. En este ejemplo se usan varias etiquetas: 'app: redis', 'role: master' y 'tier: backend'.
#               Esto va a darnos más libertad a la hora de asociar servicios/deployments/pods, a la vez que añade
#               más información al archivo YAML que servirá para entender mejor el propósito del objeto que se está 
#               creando.
#
#               Para que se produzca la asociación entre objetos, se deben verificar TODAS las etiquetas.
#
# Líneas 17-19: En la especificación de la plantilla del pod, volvemos a poner las mismas etiquetas.
#
# Líneas 22:    El contenedor ser llamará 'master'.
#
# Línea 23:     y estará basado en la imagen es 'k8s.gcr.io/redis:e2e'. 
#
# Líneas 24-30: Se especifica la contención de recursos para el contenedor. Si el servidor va sobrado de recursos, el
#               contenedor podrá usar más recursos de los que se declaran en 'requests', pero en ningún caso más de lo
#               que aparece en 'limits'.
#
#               La CPU se puede expresar en tanto por uno o, como en este caso, usando la unidad 'milis' (m). 1000 milis
#               equivalen al 100% de la CPU disponible.
#           
#               Es muy conveniente leer el siguiente artículo: https://kubernetes.io/es/docs/concepts/configuration/manage-resources-containers/

# Aplicamos el deployment:

kubectl apply -f lab-25-redis-master-deployment.yaml


# Examinamos el deployment:

kubectl get deployment redis-master-deployment


# La salida será parecida a esta:
#
# NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
# redis-master-deployment   1/1     1            1           8s


# Miramos el detalle:
# (Nota: Leer detenidamente la salida y observar la información de escalado del ReplicaSet)

kubectl describe deployment/redis-master-deployment


# La implementación ha sido una prueba, borramos el deployment desde la línea de comandos.

kubectl delete deployment/redis-master-deployment


# Comprobar que se elimina y que solo quede el servicio de Kubernetes:

kubectl get all

# Ahora vamos a hacer lo mismo pero usando un ConfigMap.
# Hay dos formas de crear un ConfigMap: Desde un archivo de texto o desde un archivo yaml.


#########################################################
# Ejercicio 2:  Creación de ConfigMap desde un archivo. #
#########################################################

# Creamos un archivo, llamado 'redis-config' y le ponemos estas dos líneas
#   maxmemory 2mb
#   maxmemory-policy allkeys-lru


# Realmente no hace falta hacerlo porque en el directorio de ejemplos ya existe ese archivo.
# Así que nos limitamos a abrirlo para comprobarlo.

code redis-config

# 'allkeys-lru' --> lru = Less Recently Used

# Para crear el ConfigMap, ejecutamos el siguiente comando.

kubectl create configmap redis-configmap-from-file --from-file=redis-config


# y ahora listamos el configmap.

kubectl get configmaps redis-configmap-from-file


# La salida debe mostrar el objeto creado:
#
# NAME                        DATA   AGE
# redis-configmap-from-file   1      6s


# Observamos contenido. Nótese que hay una clave llamada 'redis-config' y una lista con los valores 
#de la configuración:

kubectl describe configmap/redis-configmap-from-file


# Esta es la salida:
#
# Name:         redis-configmap-from-file
# Namespace:    default
# Labels:       <none>
# Annotations:  <none>
# 
# Data
# ====
# redis-config:
# ----
# maxmemory 2mb
# maxmemory-policy allkeys-lru
#
# BinaryData
# ====
# 
# Events:  <none>


# Existe otra forma de crear el objetos 'ConfigMap', mediante un archivo YAML.


# Para ello borramos el objeto recién creado:

kubectl delete configmap/redis-configmap-from-file

# En este caso partiríamos desde un archivo YAML, que tenemos disponible en la carpeta del laboratorio.
# Abrimos el archivo 'redis-config.yaml' 

code 

#
# '|-' Se utiliza para definir un string en varias líneas. Elimina el salto de 
# linea al final y los espacios en blanco si los hubiera.
code example-redis-config.yaml

# Volvemos a crear el configmap, pero esta vez directamente desde un yaml.
kubectl create -f example-redis-config.yaml

# Y lo describimos.
kubectl describe configmap/example-redis-config

# K8s tiene una opción muy útil, la '-o' ('--output'), que puede ser usada para obtener
# la salida de un objeto presente en k8s en formato YAML o JSON. Así se# puede tener 
# el archivo yaml del objeto.

# Lo prodriamos redireccionar a un archivo si lo vemos necesario.
kubectl get configmap/example-redis-config --output yaml 

# Ahora vamos a usar un configmap para pasar información al contenedor en tiempo de ejecución.
# Vamos a abrir el archivo modificado.
code redis-master-deployment_Modified.yaml

# Observar lo siguiente:
#
# Líneas 24-26: Lanza el contenedor de redis pasándole información sobre el 
#               archivo de configuración que debe utilizar: "/redis-master/redis.conf"
#
# Líneas 27-29: Para al contenedor una variable de entorno: MASTER=true
#
# Líneas 30-32: Monta un volumen llamado 'config' en la ruta '/redis-master' del
#               contenedor.
#
# Líneas 39-45: Almacena el valor de la clave 'redis-config' del configmap 'example-redis-config'
#               en el archivo 'redis.conf' en el volumen 'config'.
#
# Cuando el contenedor arranca, lee el archivo '/redis-master/redis.conf', que contiene 
# los valores del configmap que se creó.

# Desplegamos esta versión actualizada para usar configmap.
kubectl create -f redis-master-deployment_Modified.yaml

# Miramos los pods
kubectl get pods

# Ejecutamos un comando dentro del pod para comprobar si realmente ha leido los valores 
# de configuración.
#
# Cambiar el id del pod.
#
# '--' indica que lo que viene después es el comando que ejecutan los contenedores 
# del pod. En este caso, el pod tiene un único contenedor.
kubectl exec -it redis-master-<Poner aquí el id apropiado> -- redis-cli

# El comando anterior debe abrir una conexión con REDIS.
# Ejecutamos los siguientes comandos para verificar que hay 2MB y la politica es 
# LRU: Borra las claves que se usan menos Less Recently Used cuando le haga falta memoria.
CONFIG GET maxmemory
CONFIG GET maxmemory-policy

# Salimos con 'exit'

# Ahora vamos a desplegar un servicio para los pods del deployment redis-master.
code redis-master-service.yaml
kubectl apply -f redis-master-service.yaml

# Comprobamos el despliegue del servicio.
kubectl get service

# Comprobar que el tipo de servicio es 'ClusterIP', por lo que solo se puede acceder a él
# desde dentro del cluster (desde otros pods) y no desde el exterior del cluster.

# Un servicio también introduce un nombre DNS para dicho servicio, en la forma:
# <nombreServicio>.<espacioDeNombres>svc.cluster.local. Puesto que estamos usando el
# espacio de nombres 'default', la DNS del servicio 'redis-master' es:
# redis-master.default.svc.cluster.local.
#
# Para ver esto funcionando, nos metemos en el pod para ver si hay resolución DNS.
# Lo vamos a hacer con 'ping' ya que 'nslookup' no está instalado en el pod. No va 
# a haber respuesta de ping, solo nos interesa la resolución DNS.

# Listamos pods y nos quedamos con su id.
kubectl get pods
kubectl exec -it redis-master-<Poner aquí el ID apropiado> -- ping redis-master

# Comprobar que el registro A redis-master.default.svc.cluster.local. se resuelve a la IP 
# de cluster anterior. CTRL+C para salir.

# Convolución. Se completa el dominio si no se especifica completamente.
kubectl exec -it redis-master-<Poner aquí el ID apropiado> -- ping redis-master
kubectl exec -it redis-master-<Poner aquí el ID apropiado> -- ping redis-master.default
kubectl exec -it redis-master-<Poner aquí el ID apropiado> -- ping redis-master.default.svc.cluster.local

# Ahora vamos a desplegar las réplicas (2) de redis, que se sincronizarán desde redis-master.
code redis-replica-deployment.yaml
kubectl apply -f redis-replica-deployment.yaml

# Comprobamos que arrancan los pods.
kubectl get all

# Del archivo 'redis-replica-deployment.yaml' que estamos editando, destacamos:
#
# Línea 13:     Desplegamos 2 pods (2 réplicas)
#
# Línea 23:     Se usa la imagen 'follower', que se conectará a una máquina llamada 'redis-server'
#
# Línea 39-30:  Le decimos que la resolución se hace por DNS. De esta forma, los followers se conectará
#               a la IP asociada a 'redis-server', es decir a 'redis-server.default.svc.cluster.local',
#               que es la IP del pod de redis-server.


# Para que el frontend (aún por desplegar) pueda contactar con las réplicas (además del master de redis), 
# es necesario exponerlas mediante un servicio, que nos dará la respectiva ClusterIP.
kubectl apply -f redis-replica-service.yaml

# Comprobamos el despliegue.
kubectl get all

# Ahora desplegamos en frontend.
code frontend-deployment.yaml

# Lo más importante en el archivo de despliegue anterior es:
#
# Línea 11:     El número de réplicas del frontend son 3 (3 pods)
#
# Línea 8-10:   Las etiquetas son 'app: guestbook', 'tier: frontend'
#
# Línea 20:     Se está usando la imagen de contenedor: gb-frontend:v4

# en K8s existe tres formas de exponer un servicio:
#
#   ClusterIP:      Por defecto. Se crea una IP para el servicio y k8s redirige el tráfico al nodo apropiado.
#                   Al ser una IP privada, el servicio no puede ser accedido desde Internet.
#
#   NodePort:       El servicio puede ser accedido desde fuera del cluster, conectándose a la IP (y puerto)
#                   del nodo.
#
#   LoadBalancer:   Se creará un balanceador externo, con una IP pública. Se balancea entre los pods.

# Desplegamos el frontend.
kubectl apply -f frontend-deployment.yaml

# Comprobamos
kubectl get pods

# Vamos a crear un servicio de tipo 'LoadBalancer' para el frontend.
code frontend-service.yaml
kubectl create -f frontend-service.yaml

# Comprobamos los servicios. La IP Externa tarda un rato, hasta que se cree la regla en el balanceador.
kubectl get service

# Tomar nota de la IP External del frontend y conectarse con un navegador.

# Limpiamos recursos del cluster.
kubectl delete deployment frontend redis-master redis-replica
kubectl delete service frontend redis-master redis-replica

# Comprobamos que solo queda el servicio de Kubernetes
kubectl get all


#######################
# FIN DEL LABORATORIO #
#######################
